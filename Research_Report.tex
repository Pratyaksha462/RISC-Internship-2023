\documentclass{article}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
 }
\author{Pratyaksha Newalkar}
\date{June 2023}
\title{Internship Report}
\begin{document}
\maketitle


\section{Introduction}
This report provides a detailed overview of the tasks and activities undertaken during a six-week research internship conducted from 
May 15th, 2023 to June 24th, 2023. The internship focused on various aspects of image processing, computer vision, biometrics, 
and explainable AI. This report outlines the specific tasks accomplished and the progress made throughout the internship.
\section{Weeks 1-3}
During the first three weeks of the internship, the focus was on gaining a comprehensive understanding of image processing, computer vision, and various models utilized in 
the field. The following points were covered:
\subsection{Week 1: Introduction to Image Processing and Computer Vision}
During the first week of the internship, the primary focus was on understanding the fundamentals of image processing and how it is performed. The following points highlight the activities carried out:
Introduction to Image Processing:
A comprehensive study of image processing as a discipline that involves the manipulation, enhancement, and analysis of digital images.
Understanding the importance of image processing in various fields, including computer vision, medical imaging, remote sensing, and more.
Image Processing Techniques: Learning about essential image processing techniques such as image filtering, image enhancement, and image transformation.
Studying different types of filters including mean, median, Gaussian, and Sobel filters, and their applications in noise reduction and edge detection.
Exploring techniques like histogram equalization and contrast stretching for image enhancement.
Python Libraries for Image Processing:
Gaining familiarity with popular Python libraries used for image processing tasks, such as OpenCV, NumPy, and PIL (Python Imaging Library).Hands-on exercises to implement basic image processing operations using these libraries.Writing code to read, manipulate, and save images, perform various transformations, apply filters, and visualize the results.
Understanding Computer Vision:
Recognizing the relationship between image processing and computer vision as interconnected fields.
Exploring the role of computer vision in tasks such as object recognition, image segmentation, and motion tracking.
Recognizing the broader applications of computer vision in autonomous vehicles, surveillance systems, augmented reality, and more.
The activities in the first week provided a strong foundation in image processing, equipping interns with the knowledge and skills to manipulate and enhance digital images. The understanding of Python libraries and basic techniques formed the basis for further exploration into advanced computer vision tasks in the following weeks.

\subsection{Week 2: Learning Biometrics and YOLO Models}
In-depth exploration of biometrics, focusing on the identification and verification of individuals based on their physiological or behavioural characteristics.
Detailed study of different biometric modalities, including fingerprint recognition, iris recognition, and facial recognition.
Introduction to the YOLO (You Only Look Once) family of models, such as YOLOv1, YOLOv2, and YOLOv3. Understanding their architecture, key features, and training methodologies.
Hands-on experience with training and implementing YOLO models using popular frameworks like Darknet and PyTorch.
\subsection{Week 3: Advanced Topics and YOLOv8 Model}
Expanding knowledge of computer vision by diving into advanced topics such as object detection, instance segmentation, and pose estimation.
In-depth exploration of the YOLOv8 model, which represents the latest advancement in the YOLO series.
Understanding the architectural improvements and modifications introduced in YOLOv8 to enhance detection accuracy and speed.
Hands-on training of YOLOv8 on custom datasets, fine-tuning hyperparameters, and assessing the model's performance metrics.
Throughout these weeks, the focus was on understanding the inner workings of CNNs, RNNs, and the specific layers utilized in different models. Emphasis was placed on comprehending the role of convolutional layers, pooling layers, activation functions, and fully connected layers within these models.
By studying various models, including CNNs, RNNs, and the YOLO family, the internship provided a comprehensive understanding of their architectures, training methodologies, and applications in computer vision tasks. This knowledge formed a solid foundation for subsequent tasks and research conducted during the internship period.
\section{Weeks 4-5: Explainable AI in Animal Biometrics}
During weeks 4-5 of the internship, the focus was on exploring the concept of Explainable Artificial Intelligence (XAI) and its integration into the field of animal biometrics. 
\subsection{Week 4-5: Explainable AI and Animal Biometrics}
The following activities were undertaken:
\paragraph{Thorough Research on Explainable AI:} An extensive literature review was conducted to understand the principles and methodologies of Explainable AI.
Research papers, articles, and academic resources were analyzed to explore the current state of the field and identify relevant techniques and models used in XAI.
The focus was on understanding how XAI methods can provide interpretable explanations for AI systems' decision-making processes.
\paragraph{Understanding Animal Biometrics:} Comprehensive research was undertaken to gain insights into animal biometrics and its applications.
The concept of animal biometrics, including the use of unique physical characteristics and behavioural patterns for individual identification, was explored.
The potential benefits of animal biometrics in wildlife conservation, behavioural studies, and animal welfare were investigated.
\paragraph{Integration of Explainable AI in Animal Biometrics:}
The report focused on exploring the integration of XAI techniques in the field of animal biometrics. Research papers and studies were reviewed to identify existing efforts and advancements in combining XAI and animal biometrics. Different ways of understanding animal biometrics with the help of XAI were examined, aiming to shed light on the decision-making processes of AI systems deployed in wildlife monitoring and conservation efforts.
\newline
The report delved into the role of XAI in animal biometrics, highlighting its potential impact on understanding and interpreting the behaviour of AI systems used in wildlife monitoring.
Emphasis was placed on how XAI techniques can enhance the accuracy and reliability of biometric identification methods, leading to improved conservation strategies and efforts.
The importance of transparency, accountability, and trust in AI systems deployed in animal biometrics was emphasized, and XAI was presented as a tool to address these concerns.
The integration of XAI in animal biometrics holds immense potential for advancing both fields. By combining interpretability and biometric identification, researchers and conservationists can gain a deeper understanding of animal behaviour, improve conservation efforts, and ensure the ethical deployment of AI systems.

The report aimed to present a comprehensive analysis of the current state of XAI and animal biometrics, highlighting the need for collaboration and interdisciplinary research in leveraging XAI techniques for the benefit of wildlife conservation and animal welfare.

\subsection{Abstract of the report}

This report explores the intersection of Explainable Artificial Intelligence (XAI) and animal biometrics, focusing on the integration of XAI techniques in the field of animal biometrics. XAI has become increasingly important as AI systems grow in complexity and pervasiveness. By developing models that provide explanations for their decisions and actions, trust, accountability, and transparency in AI systems can be enhanced. This report examines various XAI models, including rule-based systems, decision trees, and neural networks with attention mechanisms, that have shown promise in providing interpretable explanations.

Animal biometrics, on the other hand, opens up new possibilities in wildlife conservation, behavioural studies, and animal welfare. By leveraging biometric data, such as individual identification based on unique physical traits or behavioural patterns, researchers and conservationists gain insights into animal populations, migration patterns, and species conservation efforts. The report highlights the potential benefits of integrating XAI techniques into animal biometrics, allowing for a better understanding of AI systems' decision-making processes in wildlife monitoring and conservation initiatives.

The conclusion emphasizes the need for collaboration and interdisciplinary research between the XAI and animal biometrics communities. By combining expertise, innovative approaches can be developed to improve the interpretability of AI systems and enhance the accuracy of biometric identification methods. This integration holds immense potential for advancing AI transparency and driving positive change in animal conservation efforts.
\subsection{Weeks 5-6: Database Creation and Annotation for Pedestrian Model}
During weeks 5-6 of the internship, the focus shifted towards the creation of a custom database for a pedestrian model and the annotation of videos using the Roboflow platform. The following activities were undertaken:

\paragraph{Database Creation for Pedestrian Model:}
In week 5, a specific task was assigned to create a database for a pedestrian model.
The purpose of the database was to train the model on occlusion and motion detection, enabling it to predict the direction and distance between pedestrians.
The process involved collecting or generating a dataset of pedestrian images or videos to be used for training and evaluation.
\paragraph{Annotation of Videos using Roboflow:}
In weeks 5 and 6, the focus was on annotating the collected or generated videos for the pedestrian model. The Roboflow platform, known for its annotation capabilities, was utilized for this task. Videos were processed and annotated with bounding boxes around pedestrians and other relevant annotations. The annotation process aimed to accurately identify and label pedestrians within each frame of the videos.
\paragraph{Annotation Parameters:}
The annotation process involved setting parameters such as annotating at a rate of 30 frames per second (FPS).
This higher frame rate allowed for more detailed and precise annotations, capturing the motion and position of pedestrians in the videos accurately.
\paragraph{Data Export in Different Formats:}
Once the videos were annotated, the dataset was exported in various formats suitable for training the pedestrian model.
Formats such as Darknet, YOLOv7.pytorch, and YOLOv8 were utilized, depending on the specific requirements and frameworks being used.
The creation of a custom database and the annotation of videos were crucial steps in preparing the dataset for training the pedestrian model. The meticulous annotation process using the Roboflow platform ensured accurate labelling of pedestrians, enabling the model to learn and predict pedestrian behaviour, occlusion, and motion detection.

These activities demonstrate the practical implementation of computer vision techniques and the utilization of appropriate tools and platforms to create high-quality datasets for model training and evaluation.

\section{Attachments}
Here Attached the link to all the files, codes, and assignments done during the internship period.
\href{https://drive.google.com/drive/folders/1oZdLJxZ_qfOdF_AmORsNbd4Sn4f3LThi?usp=sharing}{You can access the work here.}
\section{Conclusion:}

The internship experience provided an enriching opportunity to delve into various aspects of computer vision and artificial intelligence. Over the course of six weeks, significant progress was made in multiple areas, including image processing, learning about biometrics and computer vision models, exploring explainable AI in the context of animal biometrics, and database creation and annotation for a pedestrian model.
In conclusion, the internship provided a comprehensive learning experience encompassing image processing, computer vision models, explainable AI, and practical dataset creation. The acquired knowledge and skills can be applied to various real-world scenarios, ranging from object detection and biometrics to wildlife conservation and pedestrian detection.
\newline
The internship not only expanded technical expertise but also fostered critical thinking, problem-solving, and research skills. It highlighted the importance of interdisciplinary collaboration and staying abreast of current advancements in the field of computer vision and artificial intelligence.
\newline
Overall, the internship was a valuable journey, providing hands-on experience and deepening my understanding of the rapidly evolving field of computer vision. The gained knowledge and skills will undoubtedly serve as a strong foundation for future endeavours in the field of AI and contribute to the development of innovative solutions and advancements in the domain.



\end{document}
